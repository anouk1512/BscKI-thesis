{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import statements\n",
    "\"\"\"\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import spatial\n",
    "\n",
    "from ipynb.fs.full.Data_handling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions: \n",
    "calculate similarity between a document and a bag-of-words\n",
    "plot similarity with correspoding labels\n",
    "\"\"\"\n",
    "\n",
    "def calc_sim(bag, doc): \n",
    "    dictionary = corpora.Dictionary(bag)\n",
    "    feature_cnt = len(dictionary.token2id)\n",
    "    corpus = [dictionary.doc2bow(one) for one in bag]\n",
    "    tfidf = models.TfidfModel(corpus) \n",
    "    vector = dictionary.doc2bow(doc)\n",
    "    index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)\n",
    "    sim = index[tfidf[vector]]\n",
    "    return sim \n",
    "\n",
    "\n",
    "def plot_sim(sim, labels):\n",
    "    datafr = pd.DataFrame(dict(\n",
    "     r=sim, theta=labels))\n",
    "    fig = px.line_polar(datafr, r='r', theta='theta', line_close=True, range_r=[0,1])\n",
    "    fig.update_traces(fill='toself')\n",
    "    fig.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions to calculate similarity for documents in dictionary or list to specific bag-of-words\n",
    "\"\"\"\n",
    "\n",
    "def dict_to_sim_list(dictionary, bag): \n",
    "    list_sims = []\n",
    "    for i in range(1, len(dictionary)+1):\n",
    "        sim = calc_sim(bag, dictionary[i][1])\n",
    "        list_sims.append(sim)\n",
    "    return list_sims \n",
    "            \n",
    "def list_to_sim_list(lists, bag): \n",
    "    list_sims = []\n",
    "    for one in lists: \n",
    "        sim = calc_sim(bag, one)\n",
    "        list_sims.append(sim)\n",
    "    return list_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions to search for most related cv and vacancy in lists of similarities and plot them  \n",
    "\"\"\"\n",
    "\n",
    "# searches for best match, using Euclidean distance as measure\n",
    "def best_match(cvs, vacancies): \n",
    "    best_result = 100\n",
    "    for i_sim in range(len(cvs)):\n",
    "        for j_sim in range(len(vacancies)): \n",
    "            result = np.linalg.norm(cvs[i_sim] - vacancies[j_sim])\n",
    "            if result < best_result: \n",
    "                best_result = result \n",
    "                cv_index = i_sim\n",
    "                vac_index = j_sim  \n",
    "    return [best_result, cv_index, vac_index]\n",
    "\n",
    "# searches for worst match, using Euclidean distance as measure\n",
    "def worst_match(cvs, vacancies): \n",
    "    worst_result = 0\n",
    "    for i_sim in range(len(cvs)):\n",
    "        for j_sim in range(len(vacancies)): \n",
    "            result = np.linalg.norm(cvs[i_sim] - vacancies[j_sim])\n",
    "            if result > worst_result: \n",
    "                worst_result = result \n",
    "                cv_index = i_sim\n",
    "                vac_index = j_sim  \n",
    "    return [worst_result, cv_index, vac_index]\n",
    "\n",
    "# searches for the best vacancy for 1 CV\n",
    "def best_match_one_cv(cv, vacancies): \n",
    "    best_result = 100\n",
    "    for j_sim in range(len(vacancies)): \n",
    "        result = np.linalg.norm(np.array(cv) - np.array(vacancies[j_sim]))\n",
    "        if result < best_result: \n",
    "            best_result = result \n",
    "            vac_index = j_sim  \n",
    "    return [best_result, 0, vac_index]\n",
    "\n",
    "# searches for the n best vacancy matches for 1 CV\n",
    "def one_cv_best_vacancies(cv, vacancies, number): \n",
    "    best_matches = []\n",
    "    vacs_to_cv_dict = dict()\n",
    "    for j_sim in range(len(vacancies)): \n",
    "        result = np.linalg.norm(np.array(cv) - np.array(vacancies[j_sim]))\n",
    "        vacs_to_cv_dict[j_sim] = result\n",
    "    for i in range(number): \n",
    "        best_match = min(vacs_to_cv_dict, key=vacs_to_cv_dict.get)\n",
    "        best_matches.append([best_match, vacs_to_cv_dict[best_match]])\n",
    "        del vacs_to_cv_dict[best_match]\n",
    "    return best_matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
