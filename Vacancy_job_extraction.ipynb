{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Import statements\n",
    "\"\"\"\n",
    "\n",
    "from ipynb.fs.full.Extract_career_path import *\n",
    "from ipynb.fs.full.Data_handling import *\n",
    "from ipynb.fs.full.Competences import *\n",
    "\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Vacancies: add information about the job to the current vacancy \n",
    "\"\"\"\n",
    "\n",
    "def extract_job_vac(vac, job_database, competence_relevance_database):\n",
    "    vacancy_job = OrderedDict()\n",
    "\n",
    "    for job in job_database.keys():\n",
    "        if job == 'data scientist': \n",
    "            regular_expression = re.compile(r'data scientist | data science', re.IGNORECASE)\n",
    "        elif job == 'data analyst':\n",
    "            regular_expression = re.compile(r'data analyst | data analytics', re.IGNORECASE)\n",
    "        else: \n",
    "            regular_expression = re.compile(job, re.IGNORECASE)\n",
    "        regex_result = re.finditer(regular_expression, vac)\n",
    "\n",
    "        for result in regex_result:\n",
    "            index = job.capitalize()\n",
    "            dspp = job_database[job]['DSPP']\n",
    "            \n",
    "            if dspp != 'NA':\n",
    "                vacancy_job[index] = {'dspp': dspp}\n",
    "                vacancy_job[index].update({'relevance_scores': competence_relevance_database[dspp]})\n",
    "    \n",
    "    return vacancy_job\n",
    "\n",
    "job_database = load_jobs(JOB_DATA)\n",
    "competence_relevance_database = load_dspp_mapping(COMPETENCE_RELEVANCE)\n",
    "\n",
    "\n",
    "def search_for_job(vacancies): \n",
    "    vac_jobs = []\n",
    "    for i in range(1, len(vacancies)+1): \n",
    "        first_check = ' '.join(norm_sentence(vacancies['title'][i]))\n",
    "        info = extract_job_vac(first_check, job_database, competence_relevance_database)\n",
    "        if info == {}: \n",
    "            next_check = ' '.join(list(itertools.chain.from_iterable(ast.literal_eval(df['description'][i]))))\n",
    "            info = extract_job_vac(next_check, job_database, competence_relevance_database)\n",
    "        if info != {}: \n",
    "            vac_jobs.append(list(info.items())[0])\n",
    "        else: \n",
    "            vac_jobs.append(None)\n",
    "    vacancies['Job info'] = vac_jobs\n",
    "    return vacancies, vac_jobs\n",
    " \n",
    "vac_job_extraction, list_of_sims = search_for_job(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates the total vacancy job score\n",
    "def vac_job_cfds(jobs, similarity): \n",
    "    products = []\n",
    "    index = 0 \n",
    "    for one in jobs['Job info']:\n",
    "        dspp_sim = []\n",
    "        if one == None: \n",
    "            # if there is no job found, the similarity score is stored \n",
    "            products.append(list(similarity[index]))\n",
    "        else: \n",
    "            competences = one[1]['relevance_scores']\n",
    "            for comp in one[1]['relevance_scores']: \n",
    "                if one[1]['relevance_scores'].get(comp) == 'NA':\n",
    "                    dspp_sim.append(0) \n",
    "                else:\n",
    "                    dspp_sim.append(int(one[1]['relevance_scores'].get(comp)))\n",
    "            products.append([min((b/9)*a, 1) for a, b in zip(list(similarity[index]), dspp_sim)])\n",
    "        index += 1 \n",
    "    return products\n",
    "\n",
    "# function that calculates the normalized total vacancy job score \n",
    "def vac_job_cfds_norm(jobs, similarity): \n",
    "    products = []\n",
    "    index = 0 \n",
    "    for one in jobs['Job info']:\n",
    "        dspp_sim = []\n",
    "        if one == None: \n",
    "            products.append(list(norm_vector(similarity[index], 0.25)))\n",
    "        else: \n",
    "            competences = one[1]['relevance_scores']\n",
    "            for comp in one[1]['relevance_scores']: \n",
    "                if one[1]['relevance_scores'].get(comp) == 'NA':\n",
    "                    dspp_sim.append(0) # set to 1 when multiplying \n",
    "                else:\n",
    "                    dspp_sim.append(int(one[1]['relevance_scores'].get(comp)))\n",
    "\n",
    "            products.append([min(((b/9)*a)/0.2, 1) for a, b in zip(list(similarity[index]), dspp_sim)])\n",
    "        index += 1 \n",
    "    return products\n",
    "\n",
    "job_cfds_scores_vac = vac_job_cfds(vac_job_extraction, vac_old_sim)\n",
    "norm_job_scores = vac_job_cfds_norm(vac_job_extraction, vac_old_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_lines = []\n",
    "for line in job_cfds_scores_vac:\n",
    "    total_lines += line "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
